<main class="page-content">
    <div class="container-fluid ">  
        <!--from-back-->
     <a (click)="moveLeft()" *ngIf="showLeftArrow">
      <div class="navigation-nav nav-left">
        <i class="fa fa-chevron-left"></i>
      
      </div>
    </a>
    <a (click)="moveRight()" *ngIf="showRightArrow">
      <div class="navigation-nav nav-right">
        <i class="fa fa-chevron-right"></i>
      </div>
    </a>
        <!--from-back-->           
        <app-header [courseNumber]='8'></app-header>
        <div class="px-5 pt-5 m-h-100">
            <!--mod-->
            <div *ngIf="mod">
              <h3 class="text-blue"><strong>Stage 4 - Experience QA</strong></h3>  
              <div class="text-center "><img src="assets/tikk/Tik_ModuleIntro-08.jpg"  class="img-fluid w-75"></div>
             
            </div>
            <!--mod-->
         <!--mod1-->
         <div *ngIf="mod1"  >
            <div class="row">
                <div class="col-12 col-md-12 module-block">
                   <h3 class="text-blue pb-4"><strong>Stage Objectives </strong></h3>
<p>Validate application’s non-functional behavior such as performance, accessibility and security to meet acceptable / pre-defined benchmarks for the application.</p>
<p>Non-functional behaviors are “How” the system should perform its functions. In today’s digital age, it is not just about an application working, but more importantly, how it works. Testing an application for the how, validating application performance, security and accessibility is commonly known as Non-Functional Testing (NFT).</p>    

<p>Non-Functional Testing in DevOps is integrated across the lifecycle; here are few typical use cases:</p>
<div class="common-content">
<ul>
    <li>During build phase, it includes code-quality analysis, code profiling, single user performance validation etc.</li>
        <li>During environment setup, it covers automatic spin-off, off load generation environment, automatic environment configuration and test execution.</li>
            <li>During functional testing, it leverages automation scripts for client-side performance and accessibility assessments.</li>
        
</ul>
</div>
<div class="text-center py-4"><img src="assets/stage4/1/4Experience-Assurance.png" (click)="openImage('assets/stage4/1/4Experience-Assurance.png')" class="img-fluid pointer"></div>


               </div>
            </div>
       </div>
        <!--mod1-->


        <!--mod2-->
        <div *ngIf="mod2">
            <div class="row">
                <div class="col-12 col-md-12 module-block">
                   <h3 class="text-blue pb-4"><strong>Pipeline Overview</strong></h3>
                  
                   <p>In this stage, you will explore how experience is assured with non-functional testing. In today’s digital world, customer experience is critical for success and non-functional aspects play a significant role in an application’s functionality. You will see how an application’s performance, security and accessibility are validated in continuous pipeline with an open source tool stack and the test results updated in Azure Test Plan.</p>
                  <h4>Experience Assurance flow:</h4>
                   <div class="text-center py-4"><img src="assets/stage4/2/Azure-Diagram_Exp-Lab-04.jpg" (click)="openImage('assets/stage4/2/Azure-Diagram_Exp-Lab-04.jpg')" class="img-fluid pointer"></div>

   
                   <p>The Experience Assurance pipeline consists of two stages viz. source and build.</p>

                    <p>With every code change committed to the repository, all three tests will be triggered in a sequence. Various dependencies and commands required for these tests are defined in the buildspec.yml file in the source code repository.</p>
                    
                    <p> Performance Tests are executed with the open-source tool Jmeter (version 5.1.1). The tests will run with ten concurrent users and results will be saved in the directory performance_test_results” in the target Azure blob storage.              </p>
                   <p>
                    Performance Tests source files:
                    </p>
                 <div class="points p-4 bg-light">
                     <h6>AzureWrksp_NFTPerformance_Scenario.jmx  </h6>
<p>jmeter scenario file with required transactions.</p>                    
<h6>data_*.csv files </h6>
<p>input data files to be used inside jmeter scenario during runtime (such as credentials, sample credit cards, product names).</p>
<h6>.py files </h6>
<p>a set of python files to send data to the result dashboard and to pass / fail the build run based on few conditions such as response time SLA and transaction failures.</p>
</div>

<p><strong>Security Tests</strong> are triggered via the open-source tool owasp ZAP. These tests will perform a passive baseline security scan with predefined rules against the given URL and save the results under “security_test_results” in the target Azure blob storage.</p>

<p>Security Tests source files:</p>
<div class="points p-4 bg-light">

<h6>gen.conf  </h6>
<p>List of passive scan rules to be used by ZAP proxy during runtime.</p>

<h6>.py files  </h6>
<p>a set of python files to send data to the result dashboard and to pass / fail the build run based on rule failures (as defined in gen.conf file).</p>

</div>

<p><strong>Accessibility Tests</strong> are run using Selenium and AXE tool to analyze the application’s response against accessibility guidelines. Here, accessibility checks are done on steps executed by Selenium scripts (for each page that is rendered) and results are displayed under “accessibility_test_results” in the target Azure blob storage.</p>
<p>Accessibility Tests source files:</p>
<div class="points p-4 bg-light">
    <h6>Selenium project files </h6>
    <p>with a simple scenario and AXE tool dependencies in pom.xml to validate the accessibility in each step.</p>
</div>



               </div>
            </div>
     </div>
     <!--mod2-->

     <!--mod3-->
     <div *ngIf="mod3">
        <div class="row">
            <div class="col-12 col-md-12 module-block">
               <h3 class="text-blue pb-4"><strong>Test Plan Integration</strong></h3>
<p>Please complete the <strong>Stage 2: Post-Build QA</strong>, before commencing with this stage. This will ensure you have deployed the build on the server successfully, before executing the Experience test suits during this stage.</p>               
               <h4>Test Case</h4>

                <p>By this time, Experience Assurance related test cases should have been created in Test Plan. Go to <strong>AZURE_WORKSHOP_PROJECT>Test Plans > Test Plans</strong></p>
                <p>You should be able to view test cases related to Experience Assurance created already.</p>
                <div class="text-center py-4"><img src="assets/stage4/4.00Testsuiteoverview.jpg" (click)="openImage('assets/stage4/4.00Testsuiteoverview.jpg')" class="img-fluid pointer"></div>



           </div>
        </div>
 </div>
 <!--mod3-->



 <!--mod4-->
 <div *ngIf="mod4">
    <div class="row">
        <div class="col-12 col-md-12 module-block">
           <h3 class="text-blue pb-4"><strong>Pipeline Creation & Execution</strong></h3>
          
          
           <p><strong>1.</strong> Execute the below npm command from Cloud Shell to automatically create the Experience Assurance Release pipeline:</p>

          <div class="code" (click)="copyText(code1)"><code #code1>cd && cd azure-cli && npm run experienceqa</code> 
            <div *ngIf="copied" class="code-copied" >Copied  <i class="fas fa-check text-success"></i></div>
            <button class="btn btn-lg  code-copy"  *ngIf="!copied">
              <i class="fas fa-copy text-light"></i>
         </button> </div>
         <p>This step takes approximately 2 minutes </p>
         <div class="text-center py-4"><img src="assets/stage4/3/releasepipelinecmd.jpg" (click)="openImage('assets/stage4/3/buildpipelinecmd.jpg')" class="img-fluid pointer"></div>
         <p><strong>2. </strong>On successful creation of the pipeline, you can now view the pipline created by navigating to <strong>Azure Devops > Pipelines > Releases</strong> and selecting <strong>Experience Assurance</strong>. You will notice the pipeline failing at security testing. Refer Exhibit below for details:</p>
          <div class="text-center py-4"><img src="assets/stage4/3/release1.jpg" (click)="openImage('assets/stage4/3/release1.jpg')" class="img-fluid pointer"></div>
       <p>On clicking <strong>Release 1</strong> - Details on Stages can be seen as shown in below Exhibit.</p>
       <div class="text-center py-4"><img src="assets/stage4/4.03SecurityTestFailed.jpg" (click)="openImage('assets/stage4/4.03SecurityTestFailed.jpg')" class="img-fluid pointer"></div>

          <p>With this failure, one defect is auto-logged with state “New”. Defect can viewed in <strong>AZURE_WORKSHOP_PROJECT > Boards > Work items</strong>. Refer Exhibit below for details:</p>
          <div class="text-center py-4"><img src="assets/stage4/4.04Bug.jpg" (click)="openImage('assets/stage4/4.04Bug.jpg')" class="img-fluid pointer"></div>

          <p>Now let us fix this issue to re-execute the pipeline and check the overall non-functional impact of the code change committed.</p>
    </div>
    </div>
</div>
<!--mod4-->


<!--mod5-->
<div *ngIf="mod5">
    <div class="row">
        <div class="col-12 col-md-12 module-block">
           <h3 class="text-blue pb-4"><strong>Debugging & Reexecution</strong></h3>
           <p>Now, let us understand the nature of the failure.</p>

           <h4>Why did we encounter this failure?</h4>
           <p>To understand error better navigate to <strong>Overview -> Dashboard -> AZURE_WORKSHOP_PROJECT Team - EXPERIENCE_LAB_OVERVIEW</strong> and you can view the section Reports, as shown in below Exhibit:</p>
           <div class="text-center py-4"><img src="assets/stage3/4/dashboard.jpg" (click)="openImage('assets/stage1/4/dashboard.jpg')" class="img-fluid pointer"></div>
         
           <p>Click on <strong>Security Test</strong> Report - You can see Security test build has failed because the X-Frame-Options was not set in the response headers and this was detected by the ZAP Proxy. This rule is set as “FAIL” in the gen.conf file for ZAP tool.</p>
           <p> If you scroll down to the bottom of the file, you will notice the failure (as shown in the Exhibit below)</p>
            <div class="text-center py-4"><img src="assets/stage4/4.05Error.JPG" (click)="openImage('assets/stage4/4.05Error.JPG')" class="img-fluid pointer"></div>
            <h4>How do we fix the identified issue?</h4>
              
            <p>For now, consider this as a “False Positive” and let us fix these issues.</p>
            <p>Change the rule for X-Frame-Options Header Scanner from <strong>FAIL</strong> to <strong>WARN</strong>, so that the security test will pass with the warning and the code progresses to the next build step.</p>
            <p>Go to Overview -> Dashboards -> EXPERIENCE_LAB_OVERVIEW, and click on “Experience_QA-Fix” button at the header of Failure Fix Widget, refer the Exhibit below: </p>
            <div class="text-center py-4"><img src="assets/stage4/4.06Dashboardanderrorlink.jpg" (click)="openImage('assets/stage4/4.06Dashboardanderrorlink.jpg')" class="img-fluid pointer"></div>

            <p>It will take you to the file where fix should be applied. </p>
            <p>Click on <strong>“Edit”</strong> in the git repo and edit the file in ‘security-bug-fix’ branch.</p>

            <p>At line number:11 Change the rule for X-Frame-Options Header Scanner from <strong>FAIL</strong> to <strong>WARN</strong>. Refer the Exhibit as shown below for details:</p>
            
            <div class="text-center py-4"><img src="assets/stage4/4.08editscript.jpg" (click)="openImage('assets/stage4/4.08editscript.jpg')" class="img-fluid pointer"></div>

            <p> Provide the required details like commit message (change description) and click ‘commit’ at the bottom right corner of the page.</p>
            <div class="text-center py-4"><img src="assets/stage4/4.09commit.JPG" (click)="openImage('assets/stage4/4.09commit.JPG')" class="img-fluid pointer"></div>
            <p>The <strong>‘Successful’</strong> status is now updated for each stage, as shown below:</p>
            <div class="text-center py-4"><img src="assets/stage4/4.11newrelease.jpg" (click)="openImage('assets/stage4/4.11newrelease.jpg')" class="img-fluid pointer"></div>

            <p>Now you should see the test cases updated automatically with the result. </p>

            <p>Go to <strong>AZURE_WORKSHOP_PROJECT>Test Plans > Runs</strong></p>

            <p>You should be able to view test cases related to Experience Assurance created already. In the screen shot above and below, one run shows <strong>security failure</strong>. Then the runs are passed automatically once the code is updated and pipeline is auto-triggered. </p>
            <div class="text-center py-4"><img src="assets/stage4/4.12testruns.jpg" (click)="openImage('assets/stage4/4.12testruns.jpg')" class="img-fluid pointer"></div>
            <p>Go to <strong>AZURE_WORKSHOP_PROJECT > Boards>Work items</strong></p>
            <p>You should be able to view the previously opened defect is closed as the test case is passed. </p>
            <div class="text-center py-4"><img src="assets/stage4/4.13bugclosed.jpg" (click)="openImage('assets/stage4/4.13bugclosed.jpg')" class="img-fluid pointer"></div>

        
        
        </div>
    </div>
</div>
<!--mod5-->


<!--mod6-->
<div *ngIf="mod6">
  <div class="row">
      <div class="col-12 col-md-12 module-block">
         <h3 class="text-blue pb-4"><strong>Test Report Analysis</strong></h3>
       <!--karthik start-->
         <p>To view the Test dashboard, navigate to Overview -> Dashboards -> AZURE_WORKSHOP_PROJECT Team - Test Report Overview. You will see details as per the Exhibit below:</p>
         <div class="text-center py-4"><img src="assets/stage4/dashboard_testoverview.jpg" (click)="openImage('assets/stage4/dashboard_testoverview.jpg')" class="img-fluid pointer"></div> 
        
         <p>To view detailed reports, navigate to the Azure Dashboard. Go to Overview -> Dashboard -> AZURE_WORKSHOP_PROJECT Team - EXPERIENCE_LAB_OVERVIEW, and click on [<strong>Security Test</strong>] or [<strong>Accessibility Test</strong>] OR [<strong>Performance Test</strong>] inside the “<strong>Reports</strong>” widget. Refer Exhibit below for details:</p>
       <!--karthik end-->
         <div class="text-center py-4"><img src="assets/stage4/DashboardReport.jpg" (click)="openImage('assets/stage4/DashboardReport.jpg')" class="img-fluid pointer"></div>
        <p><strong>Accessibility Report</strong></p>
         <div class="text-center py-4"><img src="assets/stage4/accessibility.jpeg" (click)="openImage('assets/stage4/accessibility.jpeg')" class="img-fluid pointer"></div>
         <p><strong>Performance Report</strong></p>
         <div class="text-center py-4"><img src="assets/stage4/performance.jpeg" (click)="openImage('assets/stage4/performance.jpeg')" class="img-fluid pointer"></div>
         <p><strong>Security Report</strong></p>
         <div class="text-center py-4"><img src="assets/stage4/ZAP.png" (click)="openImage('assets/stage4/ZAP.png')" class="img-fluid pointer"></div>
         
              
                    
     </div>
  </div>

  <h4>Reference Links</h4>
          <p>Additionally, Practitioners can access Cognizant Thought Leadership on Customer Experience, by referring the blog by our Market Expert titled - “From ‘Ensuring Customer Experience’ to ‘Assuring Trust’: Rethinking the Role of QA”. You will find the link to the whitepaper in the Register with Cognizant page - <a href="https://www.cognizant.com/application-modernization" target="_blank" class="a">https://www.cognizant.com/application-modernization</a>. </p>

          <h4>Tool Alternate options</h4>

          <div class="table-responsive">
            <table class="table table-borderless table-light">
                  <thead>
                    <tr class="bg-blue1">
                      <th  class="text-left bg-blue2 text-center" scope="col">Stages </th>
                      <th colspan="5" class="text-center" scope="col">EXPERIENCE QA </th>
                      
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <th scope="row" class="bg-blue1 text-center">Category</th>
                      <td>Security Testing   </td>
                      <td>Accessibility Testing  </td>
                      <td>Performance Testing </td>
                     
                      
                    </tr>
                    <tr>
                      <th scope="row" class="bg-blue3 text-center">Current Tooling </th>
                      <td  class="bg-ash">ZAP    </td>
                      <td  class="bg-ash">AXE  </td>
                      <td  class="bg-ash">Jmeter   </td>
                      
                      
                    </tr>
                    <tr>
                      <th scope="row" class="bg-blue1 text-center">Alternate Tooling </th>
                      <td>Wfuzz,
                          Wapiti, 
                          W3af,
                          SQLMap 
                          
                             </td>
                      <td>ACCESSIBILITY CHECKER,
                          AATT (AUTOMATED ACCESSIBILITY TESTING TOOL), 
                          ACCESSIBILITY CHECKLIST,
                          </td>
                      <td>Apache JMeter. 
                          WebLOAD from RadView. 
                          LoadComplete from SmartBear. 
                          NeoLoad. 
                          Locust. 
                          BlazeMeter. 
                          
                      
                    
                    </tr>
                  </tbody>
                </table>

          </div>
</div>
<!--mod6-->

    </div>
    </div>
</main>